# ğŸ“‚ E-Discovery Data Processing and Analysis Pipeline


This project demonstrates an **end-to-end simulated e-discovery workflow** using Python. It covers the entire lifecycle: generating a large dataset of email records â†’ processing â†’ cleaning â†’ storing â†’ analyzing â†’ reporting â†’ visualization.

---

## ğŸ¯ Project Goal
Showcase a robust **data pipeline** for handling **Electronically Stored Information (ESI)** in legal contexts.  
Focus areas:
- Data normalization & quality assurance  
- Text preprocessing with NLP  
- Insightful analytics & visual dashboards  

---

## ğŸ“œ Description
**E-discovery (electronic discovery)** involves identifying, processing, and producing electronically stored information (ESI) for legal use.  
This notebook simulates those steps, providing a **framework for managing large-scale document metadata and text** efficiently.

---

## âœ¨ Key Features
- ğŸ”¹ **Synthetic Data Generation** with `Faker` (~50,000 records)  
- ğŸ”¹ **Normalized Relational Database Schema** using `SQLAlchemy` + SQLite  
- ğŸ”¹ **Data Cleaning** (null handling, duplicates, date standardization)  
- ğŸ”¹ **NLP Preprocessing** (tokenization, stopword removal, punctuation cleaning via `NLTK`)  
- ğŸ”¹ **Automated QA Checks** with error logging into an `Error_Log` table  
- ğŸ”¹ **Analytics & Visualization** (`Matplotlib` + `Seaborn`)  
- ğŸ”¹ **Multi-format Export** (`CSV`, `Parquet`, `JSON`)  

---

## âš™ï¸ Workflow Overview
1. **Setup** â†’ Import libraries & initialize DB  
2. **Data Generation** â†’ Create fake dataset (`Faker`)  
3. **Database & ETL** â†’ Normalize & load into SQL tables  
4. **Cleaning & Preprocessing** â†’ Fix missing values & clean text  
5. **Quality Checks** â†’ Log issues into `Error_Log`  
6. **Analysis & Visualization** â†’ Build analytical dashboard  
7. **Export** â†’ Save outputs in multiple formats  

---

## ğŸ—‚ï¸ Database Schema
**Tables:**  
- **`Documents`** â†’ Metadata (`Document ID`, `Date`, `File Type`)  
- **`Custodians`** â†’ Custodian info (`Custodian ID`, `Name`)  
- **`Emails`** â†’ Core email data (`Email ID`, linked to `Documents` & `Custodians`)  
- **`Error_Log`** â†’ QA issues (`Error ID`, `Document ID`, `Error Type`)  

---

## ğŸ“Š Visualization Dashboard
Final 2x2 dashboard includes:  
- Email volume trends  
- Custodian distributions  
- Document type breakdown  
- Error log summaries  

---

## ğŸ› ï¸ Tech Stack
- **Python 3**  
- **Pandas** â€“ Data manipulation  
- **SQLAlchemy** â€“ ORM + SQLite  
- **Faker** â€“ Data simulation  
- **NLTK** â€“ Text preprocessing  
- **Matplotlib / Seaborn** â€“ Visualization  

---

## ğŸš€ How to Run

### 1ï¸âƒ£ Prerequisites
- Python 3.x  
- Jupyter Notebook or JupyterLab  

### 2ï¸âƒ£ Install dependencies
```bash
pip install pandas sqlalchemy faker nltk matplotlib seaborn
